{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "6-YxUMpQxnU9"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Run each cell top to down in sequence**"
      ],
      "metadata": {
        "id": "dGsjXTxlxJ-G"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5sRXbbDgm8O_"
      },
      "outputs": [],
      "source": [
        "!sudo apt-get install tesseract-ocr\n",
        "!pip install pytesseract\n",
        "!pip install ultralytics==8.0.20\n",
        "\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "import pytesseract\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import re\n",
        "import ultralytics\n",
        "from ultralytics import YOLO\n",
        "import torch\n",
        "from pytesseract import Output\n",
        "import imutils"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def show_image(image):\n",
        "  resized = imutils.resize(image, width=840)\n",
        "  cv2_imshow(resized)\n",
        "\n",
        "def correct_rotation(image):\n",
        "  rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "  results = pytesseract.image_to_osd(rgb, output_type=Output.DICT)\n",
        "  rotated = imutils.rotate_bound(image, angle=results[\"rotate\"])\n",
        "  return rotated\n",
        "\n",
        "\n",
        "def crop_text_area(image):\n",
        "  original = image.copy()\n",
        "  # *********** uncomment below lines if you need this fucntion for your input image\n",
        "\n",
        "  # original = correct_rotation(original)\n",
        "  # gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "  # blur = cv2.GaussianBlur(gray, (5, 5), 0)\n",
        "  # thresh = cv2.threshold(blur, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)[1]\n",
        "\n",
        "  # horizontal_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (30,1)) # adjust value as per your input\n",
        "  # detected_lines = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, horizontal_kernel, iterations=3)\n",
        "  # cnts = cv2.findContours(detected_lines, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "  # cnts = cnts[0] if len(cnts) == 2 else cnts[1]\n",
        "  # for c in cnts:\n",
        "  #     cv2.drawContours(thresh, [c], -1, 0, -1)\n",
        "\n",
        "  # vertical_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (5,26)) # adjust value as per your input\n",
        "  # dilate = cv2.dilate(thresh, vertical_kernel, iterations=5)\n",
        "  # cnts, _ = cv2.findContours(dilate, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)[-2:]\n",
        "  # cnts = sorted(cnts, key=cv2.contourArea, reverse=True)[:-1]\n",
        "  # for c in cnts:\n",
        "  #     x,y,w,h = cv2.boundingRect(c)\n",
        "  #     cv2.rectangle(image, (x, y), (x + w, y + h), (36,255,12), 4)\n",
        "  #     ROI = original[y:y+h, x:x+w]\n",
        "  #     break\n",
        "  #return ROI\n",
        "  return original # comment this\n",
        "\n",
        "\n",
        "def get_erode_image_for_OCR(image):\n",
        "  gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "  blur_image = cv2.medianBlur(gray_image,3)\n",
        "  threshold_image = cv2.threshold(blur_image, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)[1]\n",
        "  kernel = np.ones((3,3),np.uint8)\n",
        "  erode_image = cv2.erode(threshold_image, kernel, iterations = 1)\n",
        "  return erode_image\n",
        "\n",
        "\n",
        "\n",
        "def get_image_width(image):\n",
        "  return image.shape[1]\n",
        "\n",
        "\n",
        "\n",
        "def get_OCR_data_filtered_by_RE(erode_image, draw_on_image):\n",
        "  copy_of_draw_on_image = draw_on_image.copy()\n",
        "  ocr_data = pytesseract.image_to_data(erode_image, lang='eng', output_type=Output.DICT, config='--oem 3 --psm 4')\n",
        "  ocr_n_boxes = len(ocr_data['text'])\n",
        "  number_pattern = '^\\.?\\d{1,2}\\.'\n",
        "  filtered_ocr_data = []\n",
        "\n",
        "  for i in range(ocr_n_boxes):\n",
        "    if int(ocr_data['conf'][i]) > 40:\n",
        "    \tif re.match(number_pattern, ocr_data['text'][i]):\n",
        "          (x, y, w, h) = (ocr_data['left'][i], ocr_data['top'][i], ocr_data['width'][i], ocr_data['height'][i])\n",
        "          filtered_ocr_data.append([ocr_data['left'][i], ocr_data['top'][i],int(re.match(number_pattern, ocr_data['text'][i]).group()[:-1])])\n",
        "          img = cv2.rectangle(copy_of_draw_on_image, (x, y), (x + w, y + h), (241, 153, 78), 3)\n",
        "\n",
        "  show_image(copy_of_draw_on_image)\n",
        "  return filtered_ocr_data\n",
        "\n",
        "\n",
        "\n",
        "def sort_left_right_top_bottom(coordinates, image, yolo_coordinates=False):\n",
        "  left_half_axis = []\n",
        "  right_half_axis = []\n",
        "  width = image.shape[1]\n",
        "  sorted_coordinates = []\n",
        "  for coord in coordinates:\n",
        "      if coord[0] < (width//2)-100:\n",
        "          left_half_axis.append(coord)\n",
        "      else:\n",
        "          right_half_axis.append(coord)\n",
        "\n",
        "  left_half_axis.sort(key=lambda x: x[1])\n",
        "  right_half_axis.sort(key=lambda x: x[1])\n",
        "  if not yolo_coordinates:\n",
        "    sorted_coordinates.extend([left_half_axis])\n",
        "    sorted_coordinates.extend([right_half_axis])\n",
        "  else:\n",
        "    sorted_coordinates = left_half_axis + right_half_axis\n",
        "  return sorted_coordinates\n"
      ],
      "metadata": {
        "id": "h5pjWaYHnEoz"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def xyxy2xywh(x):\n",
        "    assert x.shape[-1] == 4, f'input shape last dimension expected 4 but input shape is {x.shape}'\n",
        "    y = torch.empty_like(x) if isinstance(x, torch.Tensor) else np.empty_like(x)\n",
        "    y[..., 0] = x[..., 0]\n",
        "    y[..., 1] = x[..., 1]\n",
        "    y[..., 2] = x[..., 2] - x[..., 0]\n",
        "    y[..., 3] = x[..., 3] - x[..., 1]\n",
        "    return y\n",
        "\n",
        "\n",
        "def predict_and_YOLO_bbx(image):\n",
        "  copied_image = image.copy()\n",
        "  labels = {0: \"Cross\", 1: \"Fill\", 2: \"Strike\", 3: \"Tick\"}\n",
        "  model = YOLO(\"/content/drive/MyDrive/YOLO_170img_150epoch_06Nov/train/weights/best.pt\")\n",
        "  results = model.predict(copied_image)\n",
        "\n",
        "  selection=[]\n",
        "  selection_sorted=[]\n",
        "\n",
        "  for result in results:\n",
        "      boxes = result.boxes.cpu().numpy()\n",
        "      class_ids = result.boxes.cls.cpu().numpy()\n",
        "\n",
        "      for box, class_id in zip(boxes, class_ids):\n",
        "          if class_id != 0:\n",
        "            r = box.xyxy[0].astype(int)\n",
        "            selection.append(r.tolist())\n",
        "            cv2.rectangle(copied_image, r[:2], r[2:], (0, 255, 0), 3)\n",
        "          else:\n",
        "            cross = box.xyxy[0].astype(int)\n",
        "            cv2.rectangle(copied_image, cross[:2], cross[2:], (0, 255, 255), 3)\n",
        "\n",
        "  selection_sorted = sort_left_right_top_bottom(selection,copied_image, yolo_coordinates=True)\n",
        "  show_image(copied_image)\n",
        "  return selection_sorted\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def get_answer(image, yolo_bounding_boxes, sorted_ocr_boxes, student_script=False):\n",
        "  yolo_bounding_boxes =  [box[0].tolist() for box in [xyxy2xywh(np.array([box])) for box in yolo_bounding_boxes]]\n",
        "  answers = {}\n",
        "  thresh = 255 - cv2.threshold(cv2.cvtColor(image, cv2.COLOR_BGR2GRAY), 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)[1]\n",
        "  column_1_ocr_data_len = len(sorted_ocr_boxes[0])\n",
        "  column_2_ocr_data_len = len(sorted_ocr_boxes[1])\n",
        "  ocr_index = 1\n",
        "  go_to_2nd_column = False\n",
        "  for i in range(len(yolo_bounding_boxes)):\n",
        "    x,y,w,h = yolo_bounding_boxes[i][:4]\n",
        "    x,y,w,h = x+w+6,y-5,1000,h+6\n",
        "    ROI = thresh[y:y+h,x:x+w]\n",
        "    text_data = pytesseract.image_to_string(ROI, lang='eng',config='--oem 3 --psm 6')\n",
        "    alphanumeric_data = re.sub(r'[^a-zA-Z0-9]', '', text_data)\n",
        "    first_20_char = alphanumeric_data[:20]\n",
        "\n",
        "    question_number= None\n",
        "    if not go_to_2nd_column:\n",
        "      while not go_to_2nd_column and question_number is None and ocr_index <= column_1_ocr_data_len-1:\n",
        "        if y > sorted_ocr_boxes[0][ocr_index - 1][1] and y < sorted_ocr_boxes[0][ocr_index][1]:\n",
        "            question_number = sorted_ocr_boxes[0][ocr_index - 1][2]\n",
        "        elif y > sorted_ocr_boxes[0][ocr_index][1] and ocr_index + 1 < column_1_ocr_data_len:\n",
        "            ocr_index += 1\n",
        "        elif y > sorted_ocr_boxes[0][ocr_index][1] and ocr_index == column_1_ocr_data_len - 1:\n",
        "            question_number = sorted_ocr_boxes[0][ocr_index][2]\n",
        "        elif ocr_index == column_1_ocr_data_len - 1:\n",
        "            ocr_index = 0\n",
        "            go_to_2nd_column = True\n",
        "        else:\n",
        "          ocr_index += 1\n",
        "\n",
        "    if go_to_2nd_column:\n",
        "      while question_number is None and ocr_index <= column_2_ocr_data_len-1:\n",
        "        if y > sorted_ocr_boxes[1][ocr_index - 1][1] and y < sorted_ocr_boxes[1][ocr_index][1]:\n",
        "            question_number = sorted_ocr_boxes[1][ocr_index - 1][2]\n",
        "        elif y > sorted_ocr_boxes[1][ocr_index][1] and ocr_index + 1 < column_2_ocr_data_len:\n",
        "            ocr_index += 1\n",
        "        elif y > sorted_ocr_boxes[1][ocr_index][1] and ocr_index == column_2_ocr_data_len - 1:\n",
        "            question_number = sorted_ocr_boxes[1][ocr_index][2]\n",
        "        else:\n",
        "          ocr_index += 1\n",
        "\n",
        "    if student_script:\n",
        "      if question_number in answers:\n",
        "        answers[question_number].append((first_20_char, i))\n",
        "      else:\n",
        "        answers[question_number] = [(first_20_char, i)]\n",
        "\n",
        "    else:\n",
        "      if question_number in answers:\n",
        "        answers[question_number].append(first_20_char)\n",
        "      else:\n",
        "        answers[question_number] = [first_20_char]\n",
        "\n",
        "  return answers\n",
        "\n",
        "\n",
        "\n",
        "def compare_answers_and_get_mark(teacher_answers, student_answers):\n",
        "    student_marks = 0\n",
        "    unmacthed_yolo_index =[]\n",
        "    wrong_answers = []\n",
        "    correct_answer = []\n",
        "    not_answered = []\n",
        "\n",
        "    for key, teacher_value in teacher_answers.items():\n",
        "        if key in student_answers:\n",
        "            student_value_tuple = student_answers[key]\n",
        "            unmatched_index_list = []\n",
        "\n",
        "            for student_value, yolo_index in student_value_tuple:\n",
        "                if student_value not in teacher_value:\n",
        "                    unmatched_index_list.append(yolo_index)\n",
        "\n",
        "            if unmatched_index_list:\n",
        "                unmacthed_yolo_index.extend(unmatched_index_list)\n",
        "                wrong_answers.append(key)\n",
        "            elif len(student_value_tuple) == len(teacher_value) and not unmatched_index_list:\n",
        "                student_marks += 1\n",
        "                correct_answer.append(key)\n",
        "            else:\n",
        "              wrong_answers.append(key)\n",
        "        else:\n",
        "          not_answered.append(key)\n",
        "\n",
        "    print(\"Student marks:\", student_marks)\n",
        "    print(\"Correct answer (Qstn no):\", correct_answer)\n",
        "    print(\"Wrong answer (Qstn no):\", wrong_answers)\n",
        "    print(\"Not answered (Qstn no)\", not_answered)\n",
        "    return unmacthed_yolo_index\n",
        "\n",
        "\n",
        "def draw_red_mark_on_yolo_image(image, all_yolo_coordinates, unmatched_yolo_index):\n",
        "  copied_image = image.copy()\n",
        "  for k in unmatched_yolo_index:\n",
        "    r = all_yolo_coordinates[k]\n",
        "    cv2.rectangle(copied_image, r[:2], r[2:], (0, 0, 255), 3)\n",
        "  show_image(copied_image)"
      ],
      "metadata": {
        "id": "S8uZ6ecbp7Fr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Teacher\n",
        "teacher_original_image = crop_text_area(cv2.imread('teacher image path'))\n",
        "teacher_erode_image = get_erode_image_for_OCR(teacher_original_image)\n",
        "t_ocr_data = get_OCR_data_filtered_by_RE(teacher_erode_image, teacher_original_image)\n",
        "teacher_ocr_data = sort_left_right_top_bottom(t_ocr_data, teacher_original_image)\n",
        "\n",
        "print(\"~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\")\n",
        "print(\"Sorted OCR data:\")\n",
        "for x in teacher_ocr_data:\n",
        "  print(x)\n",
        "print(\"~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\")"
      ],
      "metadata": {
        "id": "m-LA6v9Mp92q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Teacher\n",
        "teacher_yolo_coordinates = predict_and_YOLO_bbx(teacher_original_image)\n",
        "print(\"~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\")\n",
        "print(\"Yolo coordinates (selected annotation only):\")\n",
        "for x in teacher_yolo_coordinates:\n",
        "  print(x)\n",
        "print(\"~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\")"
      ],
      "metadata": {
        "id": "XyiugkaxqAfy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Teacher\n",
        "teacher_answers = get_answer(teacher_original_image, teacher_yolo_coordinates, teacher_ocr_data)\n",
        "print(\"~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\")\n",
        "print(\"Answer strings for each question {Qstn:Ans pair}\")\n",
        "for x in teacher_answers:\n",
        "  print(x, \":\", teacher_answers[x])\n",
        "print(\"~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\")"
      ],
      "metadata": {
        "id": "hPUhWwRtqEYp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Student\n",
        "student_original_image = crop_text_area(cv2.imread('student image path'))\n",
        "student_erode_image = get_erode_image_for_OCR(student_original_image)\n",
        "\n",
        "s_ocr_data = get_OCR_data_filtered_by_RE(student_erode_image, student_original_image)\n",
        "student_ocr_data = sort_left_right_top_bottom(s_ocr_data, student_original_image)\n",
        "\n",
        "print(\"~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\")\n",
        "print(\"Sorted OCR data:\")\n",
        "for x in student_ocr_data:\n",
        "  print(x)\n",
        "print(\"~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\")"
      ],
      "metadata": {
        "id": "BlBC8_BwqKzp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Student\n",
        "student_yolo_coordinates = predict_and_YOLO_bbx(student_original_image)\n",
        "print(\"~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\")\n",
        "print(\"Yolo coordinates (selected annotation only):\")\n",
        "for x in student_yolo_coordinates:\n",
        "  print(x)\n",
        "print(\"~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\")"
      ],
      "metadata": {
        "id": "oooxuJq_qQ0x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Student\n",
        "student_answers = get_answer(student_original_image, student_yolo_coordinates, student_ocr_data, student_script=True)\n",
        "print(\"~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\")\n",
        "print(\"Answer strings for each question {Qstn:Ans pair}\")\n",
        "for x in student_answers:\n",
        "  print(x, \":\", student_answers[x])\n",
        "print(\"~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\")"
      ],
      "metadata": {
        "id": "ONZ-Yxz_qX7x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "unmatched_yolo_index = compare_answers_and_get_mark(teacher_answers, student_answers)\n",
        "draw_red_mark_on_yolo_image(student_original_image, student_yolo_coordinates, unmatched_yolo_index)"
      ],
      "metadata": {
        "id": "9LKkY1IPqb1S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Use this portion to run all the functions in a single click (Multiprocessing)"
      ],
      "metadata": {
        "id": "6-YxUMpQxnU9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# modify this to handle both input image\n",
        "\n",
        "# from multiprocessing import Process, Queue\n",
        "\n",
        "# def getOCR(student_original_image, outputOCR):\n",
        "#   student_erode_image = get_erode_image_for_OCR(student_original_image)\n",
        "#   s_ocr_data = get_OCR_data_filtered_by_RE(student_erode_image, student_original_image)\n",
        "#   student_ocr_data = sort_left_right_top_bottom(s_ocr_data, student_original_image)\n",
        "#   outputOCR.put(student_ocr_data)\n",
        "\n",
        "# def getYOLO(student_original_image, outputYOLO):\n",
        "#     student_yolo_coordinates = predict_and_YOLO_bbx(student_original_image)\n",
        "#     outputYOLO.put(student_yolo_coordinates)"
      ],
      "metadata": {
        "id": "CPeO_ZjZsi6U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# student_original_image = crop_text_area(cv2.imread('student image path '))\n",
        "\n",
        "# if __name__=='__main__':\n",
        "#     outputOCR = Queue()\n",
        "#     outputYOLO = Queue()\n",
        "\n",
        "#     student_ocr_data = Process(target = getOCR(student_original_image, outputOCR))\n",
        "#     student_ocr_data.start()\n",
        "#     student_yolo_coordinates = Process(target = getYOLO(student_original_image, outputYOLO))\n",
        "#     student_yolo_coordinates.start()\n",
        "\n",
        "#     student_answers = get_answer(student_original_image, outputYOLO.get(), outputOCR.get(), student_script=True)\n",
        "#     unmatched_yolo_index = compare_answers_and_get_mark(teacher_answers, student_answers)\n"
      ],
      "metadata": {
        "id": "0BtdLkkhsi0I"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}